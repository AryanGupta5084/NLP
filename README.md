
# ðŸ“ End to end Text-Summarizer

An end-to-end Natural Language Processing (NLP) pipeline built to summarize long text documents. This project includes modular stages for data processing, model training, and deployment via a FastAPI interface.

---

## ðŸ“š Table of Contents

- [Features](#-features)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Usage](#-usage)
- [API Endpoints](#-api-endpoints)
- [Configuration](#-configuration)
- [Dependencies](#-dependencies)
- [Examples](#-examples)
- [Troubleshooting](#-troubleshooting)
- [Contributors](#-contributors)
- [License](#-license)

---

## ðŸš€ Features

- Modularized training pipeline for ingestion, validation, transformation, training, and evaluation
- FastAPI server with endpoints to train or predict
- Custom YAML-based configuration system
- Docker support for containerized deployment
- Clean code structure for production-grade use

---

## ðŸ— Project Structure

```
â”œâ”€â”€ app.py                  # FastAPI app
â”œâ”€â”€ main.py                 # Training pipeline orchestrator
â”œâ”€â”€ Dockerfile              # For containerization
â”œâ”€â”€ params.yaml             # Model parameters
â”œâ”€â”€ config/config.yaml      # Path and data configurations
â”œâ”€â”€ src/textSummarizer/
â”‚   â”œâ”€â”€ config/             # Configuration management
â”‚   â”œâ”€â”€ conponents/         # Pipeline components (data ingestion, transformation, etc.)
â”‚   â”œâ”€â”€ constants/          # Constants
â”‚   â”œâ”€â”€ entity/             # Data schema/entities
â”‚   â”œâ”€â”€ logging/            # Logging module
â”‚   â”œâ”€â”€ pipeline/           # Stage-wise training and prediction scripts
â”‚   â””â”€â”€ utils/              # Utility functions
â””â”€â”€ research/               # Jupyter notebooks for experimentation
```

---

## ðŸ›  Installation

### 1. Clone the Repository

```bash
git clone https://github.com/AryanGupta5084/Text-Summarizer-Project.git
cd Text-Summarizer-Project
```

### 2. Create and Activate Environment

```bash
conda create -n summary python=3.9 -y
conda activate summary
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Usage

### Run FastAPI Server

```bash
python app.py
```

Open your browser at: [http://localhost:8000/docs](http://localhost:8000/docs) to access the Swagger UI.

---

## ðŸ“¡ API Endpoints

| Method | Endpoint     | Description                        |
|--------|--------------|------------------------------------|
| GET    | `/train`     | Triggers the full training pipeline |
| POST   | `/predict`   | Returns summary for given text     |
| GET    | `/`          | Redirects to docs                  |

---

## âš™ Configuration

- `config/config.yaml`: Paths to data directories
- `params.yaml`: Hyperparameters for model training

---

## ðŸ“¦ Dependencies

- `FastAPI`
- `uvicorn`
- `pydantic`
- `PyYAML`
- `transformers` or any summarization-compatible NLP library
- `scikit-learn`, `pandas`, `numpy`

> Install using:  
```bash
pip install -r requirements.txt
```

---

## ðŸ§ª Examples

Example `POST` request to `/predict`:

```json
{
  "text": "Text summarization is a Natural Language Processing (NLP) task..."
}
```

Response:
```json
{
  "summary": "Text summarization is an NLP task..."
}
```

---

## ðŸ›  Troubleshooting

- âš  **No response from `/predict`**: Ensure the model is trained (`/train`) before predicting.
- âš  **Module errors**: Double-check environment paths and virtual environment activation.
- âš  **Docker issues**: Ensure Docker is installed and build the container with `docker build -t summarizer .`

---

## ðŸ‘¨â€ðŸ’» Contributors

- **Aryan Gupta**  
  ðŸ“§ ag5787842@gmail.com

---

## ðŸ“„ License

This project is licensed under the terms of the [LICENSE](./LICENSE) file in this repository.

> Â© 2025 Aryan Gupta. All rights reserved.
